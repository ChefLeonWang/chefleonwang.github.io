<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"><channel><title>Chef Leon</title><description>å¿ƒå¿ƒå¿µå¿µåœ°ä¸­æµ·</description><link>https://chefleonwang.github.io/</link><item><title>Again Dive into TRPO: Understanding TRPO from Macro to Micro</title><link>https://chefleonwang.github.io/posts/deeper_into_trpo_2/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/deeper_into_trpo_2/</guid><description>How Taylor expansion, KL divergence, and the Fisher matrix fit together in Trust Region Policy Optimization.</description><pubDate>Thu, 22 May 2025 19:30:00 GMT</pubDate></item><item><title>First Delve into Natural Policy Gradient</title><link>https://chefleonwang.github.io/posts/natural_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/natural_gradient/</guid><description>A complete introduction to the natural policy gradient: motivation, mathematics, and intuitive meaning.</description><pubDate>Thu, 22 May 2025 19:00:00 GMT</pubDate></item><item><title>Again into policy iteration and policy gradient: A Deep Learning Analogy</title><link>https://chefleonwang.github.io/posts/again_policy_iteration_to_policy_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/again_policy_iteration_to_policy_gradient/</guid><description>How policy iteration relates to classical optimization and policy gradient to deep learning, with full mathematical detail.</description><pubDate>Thu, 22 May 2025 11:30:00 GMT</pubDate></item><item><title>Dive into TRPO</title><link>https://chefleonwang.github.io/posts/deeper_into_trpo/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/deeper_into_trpo/</guid><description>A detailed walkthrough of TRPO&apos;s constrained optimization strategy, natural gradient step, and KL trust region.</description><pubDate>Tue, 20 May 2025 16:00:00 GMT</pubDate></item><item><title>TRPO to PPO: Distribution Mismatch and Why Small Policy Updates Work</title><link>https://chefleonwang.github.io/posts/important_sampling_and-trust_region/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/important_sampling_and-trust_region/</guid><description>Combining practical tricks and theoretical bounds to justify ignoring distribution mismatch in policy gradient updates.</description><pubDate>Tue, 20 May 2025 14:00:00 GMT</pubDate></item><item><title>Policy Iteration â†’ Policy Gradient: A Natural Evolution</title><link>https://chefleonwang.github.io/posts/policy_iteration_to_policy_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/policy_iteration_to_policy_gradient/</guid><description>Why policy gradient methods emerged from the limitations of classical policy iteration, especially in continuous or high-dimensional action spaces. Includes key math and references.</description><pubDate>Mon, 19 May 2025 16:30:00 GMT</pubDate></item><item><title>DDQN vs. DDPG: Understanding Two Powerful Off-Policy RL Algorithms</title><link>https://chefleonwang.github.io/posts/ddqnandddpg/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/ddqnandddpg/</guid><description>A clear side-by-side comparison between Double Deep Q-Networks (DDQN) and Deep Deterministic Policy Gradient (DDPG), highlighting the key differences in structure, use cases, and action spaces.</description><pubDate>Mon, 19 May 2025 14:36:00 GMT</pubDate></item><item><title>From DQN to Double DQN: Fixing Overestimation Bias</title><link>https://chefleonwang.github.io/posts/dqn_to_ddqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/dqn_to_ddqn/</guid><description>Understand the overestimation problem in Deep Q-Learning and how Double DQN (DDQN) provides a simple but powerful fix by decoupling action selection and evaluation.</description><pubDate>Mon, 19 May 2025 11:00:00 GMT</pubDate></item><item><title>Siamese Networks and DQN: Understanding the Role of Target Networks</title><link>https://chefleonwang.github.io/posts/siamese_networks_and_dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/siamese_networks_and_dqn/</guid><description>Explore how Deep Q-Networks (DQN) resemble Siamese networks, and learn the strategies used to update main and target networks for stable training.</description><pubDate>Sun, 18 May 2025 10:30:00 GMT</pubDate></item><item><title>Exploration Strategies in DQN: Epsilon-Greedy vs Boltzmann</title><link>https://chefleonwang.github.io/posts/dqn_exploration_methods/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/dqn_exploration_methods/</guid><description>Understanding the two most common exploration strategies used in Deep Q-Learning: epsilon-greedy and Boltzmann (softmax) exploration.</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Critic and DQN</title><link>https://chefleonwang.github.io/posts/critic-vs-dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/critic-vs-dqn/</guid><description>Critic åœ¨ Actor-Critic ä¸­æ˜¯ä¸ªæ‰“åˆ†æœºå™¨ï¼Œè€Œåœ¨ DQN é‡Œå®ƒç›´æ¥æ‹¿ Q å€¼åšå†³ç­–ã€‚</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Is DQN an Online Q-learning Algorithm? Exploring the Boundary</title><link>https://chefleonwang.github.io/posts/online_qlearning_and_dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/online_qlearning_and_dqn/</guid><description>Is DQN an online Q-learning method? What if the minibatch size is 1? This post explores when DQN behaves like an online algorithm and clarifies how it connects to classical Q-learning.</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Brined, Buttermilk Fried Chicken</title><link>https://chefleonwang.github.io/posts/best_fried_chicken/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/best_fried_chicken/</guid><description>å¥½åƒğŸ˜‹ğŸ˜‹ğŸ˜‹</description><pubDate>Sat, 17 May 2025 18:08:53 GMT</pubDate></item><item><title>Morning Supplements to WAKE UP</title><link>https://chefleonwang.github.io/posts/morning_supplements/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/morning_supplements/</guid><description>è®°å½•æˆ‘æ¸…æ™¨æœç”¨çš„è¡¥å‰‚ç»„åˆï¼Œç”¨äºä¼˜åŒ–ç²¾ç¥çŠ¶æ€ã€ä»£è°¢æ•ˆç‡ã€å‡è„‚æ‰§è¡ŒåŠ›ä¸ç¥ç»ç³»ç»Ÿç¨³å®šæ€§ã€‚ Optimizing mental clarity, metabolic efficiency, fat loss execution, and nervous system balance.
</description><pubDate>Sat, 17 May 2025 09:00:00 GMT</pubDate></item><item><title>Lemon Salt Gelato</title><link>https://chefleonwang.github.io/posts/lemonsaltgelato/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/lemonsaltgelato/</guid><description>A refreshing gelato with a hint of lemon and sea salt.</description><pubDate>Fri, 16 May 2025 09:00:00 GMT</pubDate></item><item><title>from markov process to non markovian</title><link>https://chefleonwang.github.io/posts/markov_process/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/markov_process/</guid><description>ä¸ç½®å¯å¦</description><pubDate>Fri, 16 May 2025 09:00:00 GMT</pubDate></item></channel></rss>