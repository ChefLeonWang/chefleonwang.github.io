<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"><channel><title>Chef Leon</title><description>心心念念地中海</description><link>https://chefleonwang.github.io/</link><item><title>Again Dive into TRPO: Understanding TRPO from Macro to Micro</title><link>https://chefleonwang.github.io/posts/deeper_into_trpo_2/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/deeper_into_trpo_2/</guid><description>How Taylor expansion, KL divergence, and the Fisher matrix fit together in Trust Region Policy Optimization.</description><pubDate>Thu, 22 May 2025 19:30:00 GMT</pubDate></item><item><title>First Delve into Natural Policy Gradient</title><link>https://chefleonwang.github.io/posts/natural_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/natural_gradient/</guid><description>A complete introduction to the natural policy gradient: motivation, mathematics, and intuitive meaning.</description><pubDate>Thu, 22 May 2025 19:00:00 GMT</pubDate></item><item><title>Again into policy iteration and policy gradient: A Deep Learning Analogy</title><link>https://chefleonwang.github.io/posts/again_policy_iteration_to_policy_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/again_policy_iteration_to_policy_gradient/</guid><description>How policy iteration relates to classical optimization and policy gradient to deep learning, with full mathematical detail.</description><pubDate>Thu, 22 May 2025 11:30:00 GMT</pubDate></item><item><title>Dive into TRPO</title><link>https://chefleonwang.github.io/posts/deeper_into_trpo/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/deeper_into_trpo/</guid><description>A detailed walkthrough of TRPO&apos;s constrained optimization strategy, natural gradient step, and KL trust region.</description><pubDate>Tue, 20 May 2025 16:00:00 GMT</pubDate></item><item><title>TRPO to PPO: Distribution Mismatch and Why Small Policy Updates Work</title><link>https://chefleonwang.github.io/posts/important_sampling_and-trust_region/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/important_sampling_and-trust_region/</guid><description>Combining practical tricks and theoretical bounds to justify ignoring distribution mismatch in policy gradient updates.</description><pubDate>Tue, 20 May 2025 14:00:00 GMT</pubDate></item><item><title>Policy Iteration → Policy Gradient: A Natural Evolution</title><link>https://chefleonwang.github.io/posts/policy_iteration_to_policy_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/policy_iteration_to_policy_gradient/</guid><description>Why policy gradient methods emerged from the limitations of classical policy iteration, especially in continuous or high-dimensional action spaces. Includes key math and references.</description><pubDate>Mon, 19 May 2025 16:30:00 GMT</pubDate></item><item><title>DDQN vs. DDPG: Understanding Two Powerful Off-Policy RL Algorithms</title><link>https://chefleonwang.github.io/posts/ddqnandddpg/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/ddqnandddpg/</guid><description>A clear side-by-side comparison between Double Deep Q-Networks (DDQN) and Deep Deterministic Policy Gradient (DDPG), highlighting the key differences in structure, use cases, and action spaces.</description><pubDate>Mon, 19 May 2025 14:36:00 GMT</pubDate></item><item><title>From DQN to Double DQN: Fixing Overestimation Bias</title><link>https://chefleonwang.github.io/posts/dqn_to_ddqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/dqn_to_ddqn/</guid><description>Understand the overestimation problem in Deep Q-Learning and how Double DQN (DDQN) provides a simple but powerful fix by decoupling action selection and evaluation.</description><pubDate>Mon, 19 May 2025 11:00:00 GMT</pubDate></item><item><title>Siamese Networks and DQN: Understanding the Role of Target Networks</title><link>https://chefleonwang.github.io/posts/siamese_networks_and_dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/siamese_networks_and_dqn/</guid><description>Explore how Deep Q-Networks (DQN) resemble Siamese networks, and learn the strategies used to update main and target networks for stable training.</description><pubDate>Sun, 18 May 2025 10:30:00 GMT</pubDate></item><item><title>Exploration Strategies in DQN: Epsilon-Greedy vs Boltzmann</title><link>https://chefleonwang.github.io/posts/dqn_exploration_methods/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/dqn_exploration_methods/</guid><description>Understanding the two most common exploration strategies used in Deep Q-Learning: epsilon-greedy and Boltzmann (softmax) exploration.</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Critic and DQN</title><link>https://chefleonwang.github.io/posts/critic-vs-dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/critic-vs-dqn/</guid><description>Critic 在 Actor-Critic 中是个打分机器，而在 DQN 里它直接拿 Q 值做决策。</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Is DQN an Online Q-learning Algorithm? Exploring the Boundary</title><link>https://chefleonwang.github.io/posts/online_qlearning_and_dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/online_qlearning_and_dqn/</guid><description>Is DQN an online Q-learning method? What if the minibatch size is 1? This post explores when DQN behaves like an online algorithm and clarifies how it connects to classical Q-learning.</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Brined, Buttermilk Fried Chicken</title><link>https://chefleonwang.github.io/posts/best_fried_chicken/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/best_fried_chicken/</guid><description>好吃😋😋😋</description><pubDate>Sat, 17 May 2025 18:08:53 GMT</pubDate></item><item><title>Morning Supplements to WAKE UP</title><link>https://chefleonwang.github.io/posts/morning_supplements/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/morning_supplements/</guid><description>记录我清晨服用的补剂组合，用于优化精神状态、代谢效率、减脂执行力与神经系统稳定性。 Optimizing mental clarity, metabolic efficiency, fat loss execution, and nervous system balance.
</description><pubDate>Sat, 17 May 2025 09:00:00 GMT</pubDate></item><item><title>Lemon Salt Gelato</title><link>https://chefleonwang.github.io/posts/lemonsaltgelato/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/lemonsaltgelato/</guid><description>A refreshing gelato with a hint of lemon and sea salt.</description><pubDate>Fri, 16 May 2025 09:00:00 GMT</pubDate></item><item><title>from markov process to non markovian</title><link>https://chefleonwang.github.io/posts/markov_process/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/markov_process/</guid><description>不置可否</description><pubDate>Fri, 16 May 2025 09:00:00 GMT</pubDate></item></channel></rss>