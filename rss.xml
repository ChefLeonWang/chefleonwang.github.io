<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"><channel><title>Chef Leon</title><description>ÂøÉÂøÉÂøµÂøµÂú∞‰∏≠Êµ∑</description><link>https://chefleonwang.github.io/</link><item><title>Nature Science to Model-Based RL: Building a World Model</title><link>https://chefleonwang.github.io/posts/nature-science-to-model-based-rl_-building-a-world-model/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/nature-science-to-model-based-rl_-building-a-world-model/</guid><description>Exploring the deep parallels between natural science and model-based reinforcement learning through the lens of world models.</description><pubDate>Mon, 11 Aug 2025 11:30:00 GMT</pubDate></item><item><title>Who created universe</title><link>https://chefleonwang.github.io/posts/who_created/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/who_created/</guid><description>If we are created, who created the creator?</description><pubDate>Thu, 31 Jul 2025 11:30:00 GMT</pubDate></item><item><title>The Paradox of Interpretability: When Humans Become the Interpreters of Deep Models</title><link>https://chefleonwang.github.io/posts/interpretability/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/interpretability/</guid><description>bibibubu</description><pubDate>Wed, 25 Jun 2025 11:30:00 GMT</pubDate></item><item><title>Maximum Margin Principle in SVM and IRL</title><link>https://chefleonwang.github.io/posts/maximum_margin_principle/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/maximum_margin_principle/</guid><description>A geometric and mathematical deep dive into the role of margin-based reasoning in classification and inverse reinforcement learning.</description><pubDate>Mon, 23 Jun 2025 11:30:00 GMT</pubDate></item><item><title>From Information Theory to Practical RL</title><link>https://chefleonwang.github.io/posts/from_information_theory_to_practical/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/from_information_theory_to_practical/</guid><description>This post introduces how core concepts from information theory like mutual information and information gain are approximated and implemented in real-world reinforcement learning algorithms.</description><pubDate>Tue, 10 Jun 2025 09:00:00 GMT</pubDate></item><item><title>Smooth trasition: Convex Combination and other methods</title><link>https://chefleonwang.github.io/posts/convex_combination/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/convex_combination/</guid><description>An overview of convex combinations and their practical applications in optimization, deep learning, and RL.</description><pubDate>Sat, 07 Jun 2025 11:30:00 GMT</pubDate></item><item><title>Why Backpropagation Fails in Multi-Model Systems</title><link>https://chefleonwang.github.io/posts/model_free_for_model_based_rl/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/model_free_for_model_based_rl/</guid><description>Exploring the practical limitations of backpropagation in model-based reinforcement learning and the benefits of combining model-free techniques.</description><pubDate>Tue, 03 Jun 2025 11:30:00 GMT</pubDate></item><item><title>Planning in Latent Space: Model-Based RL beyond Observations</title><link>https://chefleonwang.github.io/posts/latent_space_planning/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/latent_space_planning/</guid><description>An end-to-end explanation of why and how modern model-based reinforcement learning leverages latent state space modeling for stability, scalability, and differentiable planning.</description><pubDate>Sun, 01 Jun 2025 00:00:00 GMT</pubDate></item><item><title>Define Uncertainty: Aleatoric and Epistemic</title><link>https://chefleonwang.github.io/posts/uncertainty_aleatoric_and_epistemic/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/uncertainty_aleatoric_and_epistemic/</guid><description>A detailed explanation of aleatoric and epistemic uncertainty, and practical methods to estimate them in deep learning.</description><pubDate>Sat, 31 May 2025 10:00:00 GMT</pubDate></item><item><title>Morning Supplements to WAKE UP</title><link>https://chefleonwang.github.io/posts/morning_supplements/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/morning_supplements/</guid><description>ËÆ∞ÂΩïÊàëÊ∏ÖÊô®ÊúçÁî®ÁöÑË°•ÂâÇÁªÑÂêàÔºåÁî®‰∫é‰ºòÂåñÁ≤æÁ•ûÁä∂ÊÄÅ„ÄÅ‰ª£Ë∞¢ÊïàÁéá„ÄÅÂáèËÑÇÊâßË°åÂäõ‰∏éÁ•ûÁªèÁ≥ªÁªüÁ®≥ÂÆöÊÄß„ÄÇ Optimizing mental clarity, metabolic efficiency, fat loss execution, and nervous system balance.
</description><pubDate>Mon, 26 May 2025 09:00:00 GMT</pubDate></item><item><title>MCTS and UCT: Monte Carlo Tree Search in Discrete Action Spaces</title><link>https://chefleonwang.github.io/posts/mcts_and_uct/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/mcts_and_uct/</guid><description>A detailed walk-through of MCTS in discrete settings, including algorithmic steps, math formulations, and tree policy intuition.</description><pubDate>Fri, 23 May 2025 23:00:00 GMT</pubDate></item><item><title>Open-Loop vs Closed-Loop Planning</title><link>https://chefleonwang.github.io/posts/open_loop_and_close_loop/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/open_loop_and_close_loop/</guid><description>This post explores the core differences between open-loop and closed-loop planning, their underlying assumptions, typical algorithms, and use cases.</description><pubDate>Fri, 23 May 2025 22:30:00 GMT</pubDate></item><item><title>Third dive into TRPO:Trust Region Optimization Mathematical Foundations</title><link>https://chefleonwang.github.io/posts/deeper_into_trpo_3/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/deeper_into_trpo_3/</guid><description>A standalone mathematical and intuitive guide to trust region optimization and its relevance to safe policy updates.</description><pubDate>Thu, 22 May 2025 20:30:00 GMT</pubDate></item><item><title>Model-Free vs Model-Based RL: Black Boxes, Internal Models, and the Naming Irony</title><link>https://chefleonwang.github.io/posts/model_free_and_model_based/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/model_free_and_model_based/</guid><description>A detailed, intuitive and technical comparison between model-free and model-based reinforcement learning.</description><pubDate>Thu, 22 May 2025 20:00:00 GMT</pubDate></item><item><title>Again dive into TRPO: Understanding TRPO from Macro to Micro</title><link>https://chefleonwang.github.io/posts/deeper_into_trpo_2/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/deeper_into_trpo_2/</guid><description>How Taylor expansion, KL divergence, and the Fisher matrix fit together in Trust Region Policy Optimization.</description><pubDate>Thu, 22 May 2025 19:30:00 GMT</pubDate></item><item><title>First Delve into Natural Policy Gradient</title><link>https://chefleonwang.github.io/posts/natural_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/natural_gradient/</guid><description>A complete introduction to the natural policy gradient: motivation, mathematics, and intuitive meaning.</description><pubDate>Thu, 22 May 2025 19:00:00 GMT</pubDate></item><item><title>Again into policy iteration and policy gradient: A Deep Learning Analogy</title><link>https://chefleonwang.github.io/posts/again_policy_iteration_to_policy_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/again_policy_iteration_to_policy_gradient/</guid><description>How policy iteration relates to classical optimization and policy gradient to deep learning, with full mathematical detail.</description><pubDate>Thu, 22 May 2025 11:30:00 GMT</pubDate></item><item><title>Dive into TRPO</title><link>https://chefleonwang.github.io/posts/deeper_into_trpo/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/deeper_into_trpo/</guid><description>A detailed walkthrough of TRPO&apos;s constrained optimization strategy, natural gradient step, and KL trust region.</description><pubDate>Tue, 20 May 2025 16:00:00 GMT</pubDate></item><item><title>TRPO to PPO: Distribution Mismatch and Why Small Policy Updates Work</title><link>https://chefleonwang.github.io/posts/important_sampling_and-trust_region/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/important_sampling_and-trust_region/</guid><description>Combining practical tricks and theoretical bounds to justify ignoring distribution mismatch in policy gradient updates.</description><pubDate>Tue, 20 May 2025 14:00:00 GMT</pubDate></item><item><title>Policy Iteration ‚Üí Policy Gradient: A Natural Evolution</title><link>https://chefleonwang.github.io/posts/policy_iteration_to_policy_gradient/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/policy_iteration_to_policy_gradient/</guid><description>Why policy gradient methods emerged from the limitations of classical policy iteration, especially in continuous or high-dimensional action spaces. Includes key math and references.</description><pubDate>Mon, 19 May 2025 16:30:00 GMT</pubDate></item><item><title>DDQN vs. DDPG: Understanding Two Powerful Off-Policy RL Algorithms</title><link>https://chefleonwang.github.io/posts/ddqnandddpg/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/ddqnandddpg/</guid><description>A clear side-by-side comparison between Double Deep Q-Networks (DDQN) and Deep Deterministic Policy Gradient (DDPG), highlighting the key differences in structure, use cases, and action spaces.</description><pubDate>Mon, 19 May 2025 14:36:00 GMT</pubDate></item><item><title>From DQN to Double DQN: Fixing Overestimation Bias</title><link>https://chefleonwang.github.io/posts/dqn_to_ddqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/dqn_to_ddqn/</guid><description>Understand the overestimation problem in Deep Q-Learning and how Double DQN (DDQN) provides a simple but powerful fix by decoupling action selection and evaluation.</description><pubDate>Mon, 19 May 2025 11:00:00 GMT</pubDate></item><item><title>Siamese Networks and DQN: Understanding the Role of Target Networks</title><link>https://chefleonwang.github.io/posts/siamese_networks_and_dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/siamese_networks_and_dqn/</guid><description>Explore how Deep Q-Networks (DQN) resemble Siamese networks, and learn the strategies used to update main and target networks for stable training.</description><pubDate>Sun, 18 May 2025 10:30:00 GMT</pubDate></item><item><title>Exploration Strategies in DQN: Epsilon-Greedy vs Boltzmann</title><link>https://chefleonwang.github.io/posts/dqn_exploration_methods/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/dqn_exploration_methods/</guid><description>Understanding the two most common exploration strategies used in Deep Q-Learning: epsilon-greedy and Boltzmann (softmax) exploration.</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Critic and DQN</title><link>https://chefleonwang.github.io/posts/critic-vs-dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/critic-vs-dqn/</guid><description>Critic Âú® Actor-Critic ‰∏≠ÊòØ‰∏™ÊâìÂàÜÊú∫Âô®ÔºåËÄåÂú® DQN ÈáåÂÆÉÁõ¥Êé•Êãø Q ÂÄºÂÅöÂÜ≥Á≠ñ„ÄÇ</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Is DQN an Online Q-learning Algorithm? Exploring the Boundary</title><link>https://chefleonwang.github.io/posts/online_qlearning_and_dqn/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/online_qlearning_and_dqn/</guid><description>Is DQN an online Q-learning method? What if the minibatch size is 1? This post explores when DQN behaves like an online algorithm and clarifies how it connects to classical Q-learning.</description><pubDate>Sun, 18 May 2025 09:00:00 GMT</pubDate></item><item><title>Brined, Buttermilk Fried Chicken</title><link>https://chefleonwang.github.io/posts/best_fried_chicken/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/best_fried_chicken/</guid><description>Â•ΩÂêÉüòãüòãüòã</description><pubDate>Sat, 17 May 2025 18:08:53 GMT</pubDate></item><item><title>from markov process to non markovian</title><link>https://chefleonwang.github.io/posts/markov_process/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/markov_process/</guid><description>‰∏çÁΩÆÂèØÂê¶</description><pubDate>Fri, 16 May 2025 09:00:00 GMT</pubDate></item><item><title>Lemon Salt Gelato</title><link>https://chefleonwang.github.io/posts/lemonsaltgelato/</link><guid isPermaLink="true">https://chefleonwang.github.io/posts/lemonsaltgelato/</guid><description>A refreshing gelato with a hint of lemon and sea salt.</description><pubDate>Fri, 16 May 2025 09:00:00 GMT</pubDate></item></channel></rss>